{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO206B Fall 2022 Assignment 3\n",
    "\n",
    "Sentiment analysis uses natural language processing, text analysis, and other methods to systematically identify, extract, quantify, and study affective information in many different contexts. In this assignment, you will perform a simple sentiment analysis on different texts, ranging from tweets to tomes. In the process, you will learn about the design, implementation, and performance evaluation of search algorithms and data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Tweets (5 points)\n",
    "\n",
    "You are given a [list of famous (or infamous) tweets](https://people.ischool.berkeley.edu/~chuang/i206/b3/tweets.txt). from the colored history of Twitter. Your task is to compute the sentiment of each tweet based on the sentiment scores of the words in the tweet. For this part of the assignment, the sentiment of a tweet is simply the sum of the sentiment scores for each word in the tweet.\n",
    "\n",
    "You will use a hand-coded [sentiment lexicon developed by Finn Årup Nielsen](https://github.com/fnielsen/afinn). that contains a list of ~2,400 English words with sentiment scores ranging from -5 (most negative) to 5 (most positive). Your program will read the file [AFINN-111.txt](https://people.ischool.berkeley.edu/~chuang/i206/b3/AFINN-111.txt) into a dictionary data structure. (Note that the file is tab delimited, so you will want to use the `“\\t”` argument for your split method.)\n",
    "\n",
    "For each of the ten tweets, you should split the tweet into its component words, removing any whitespaces and punctuations, and converting the words to lowercase. Then, you look up the sentiment score for each word in the dictionary. If a word is not found, its score is zero. The sentiment score of the tweet is the sum of the scores of the individual words. Print the tweet and its sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip word of punctuation and convert to all lower-case\n",
    "def stripWord( w ):\n",
    "    w = w.replace( \".\", \"\" )\n",
    "    w = w.replace( \",\", \"\" )\n",
    "    w = w.replace( \";\", \"\" )\n",
    "    w = w.replace( \":\", \"\" )\n",
    "    w = w.replace( \"'\", \"\" )\n",
    "    w = w.replace( \"&\", \"\" )\n",
    "    w = w.replace( \"\\n\", \"\" )\n",
    "    w = w.lower()\n",
    "    return( w )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 0 : just setting up my twttr\n",
      "Tweet sentiment: 0 \n",
      "\n",
      "Tweet 1 : there's a plane in the Hudson. I'm on the ferry going to pick up the people. Crazy.\n",
      "Tweet sentiment: -2 \n",
      "\n",
      "Tweet 2 : Are you ready to celebrate? Well, get ready: We have ICE!!!!! Yes, ICE, *WATER ICE* on Mars! woot!!! Best day ever!!\n",
      "Tweet sentiment: 4 \n",
      "\n",
      "Tweet 3 : Arrested\n",
      "Tweet sentiment: -3 \n",
      "\n",
      "Tweet 4 : HI TWITTERS . THANK YOU FOR A WARM WELCOME. FEELING REALLY 21ST CENTURY .\n",
      "Tweet sentiment: 6 \n",
      "\n",
      "Tweet 5 : Hello Twitterverse! We r now LIVE tweeting from the International Space Station -- the 1st live tweet from Space! :) More soon, send your ?s\n",
      "Tweet sentiment: 0 \n",
      "\n",
      "Tweet 6 : OK, What The Hell Is \"Weird Twitter\"?\n",
      "Tweet sentiment: -4 \n",
      "\n",
      "Tweet 7 : Please retweet this to spread awareness for retweets.\n",
      "Tweet sentiment: 1 \n",
      "\n",
      "Tweet 8 : If only Bradley's arm was longer. Best photo ever. #oscars\n",
      "Tweet sentiment: 3 \n",
      "\n",
      "Tweet 9 : admiring my award winning masterpiece -- super stunning roflcopter tweet ftw woohoo!\n",
      "Tweet sentiment: 28 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the function\n",
    "def tweet_sentiment(in_file):\n",
    "    # open the file\n",
    "    lexicon_contents = open(\"AFINN-111.txt\", \"r\")\n",
    "    # turn it into a list\n",
    "    file_lines = lexicon_contents.readlines()\n",
    "\n",
    "    # trace trace trace\n",
    "    #print(file_lines)\n",
    "\n",
    "    # start the dictionary\n",
    "    lex_dict = {}\n",
    "\n",
    "    # strip the lexicon into list of list \n",
    "    for i in range(len(file_lines)):\n",
    "        file_lines[i] = file_lines[i].strip().split(\"\\t\")\n",
    "        # add the keys/values to the dictionary \n",
    "        lex_dict[file_lines[i][0]] = int(file_lines[i][1])\n",
    "\n",
    "    #print(file_lines)\n",
    "    #print(lex_dict)\n",
    "\n",
    "    # close the file\n",
    "    lexicon_contents.close()\n",
    "\n",
    "    ### SENTIMENT DICTIONARY IS MADE\n",
    "\n",
    "    # Now it's time for reading the actual file of tweets\n",
    "    tweet_contents = open(in_file, \"r\")\n",
    "    tweet_lines = tweet_contents.readlines()\n",
    "\n",
    "    # loop over contents\n",
    "    for i in range(len(tweet_lines)):\n",
    "        # strip the newline\n",
    "        tweet_lines[i] = tweet_lines[i].strip()\n",
    "        # print out the tweet\n",
    "        print(\"Tweet\", i, \":\", tweet_lines[i])\n",
    "        # now we strip into component words\n",
    "        tweet_lines[i] = tweet_lines[i].split()\n",
    "        \n",
    "        \n",
    "        #define the sentiment\n",
    "        sentiment_max = 0\n",
    "\n",
    "        # now we need to add up the sentiment of all words\n",
    "        for j in range(len(tweet_lines[i])):\n",
    "            # strip word it\n",
    "            the_word = stripWord(tweet_lines[i][j])\n",
    "            \n",
    "            # check to see if it's in there\n",
    "            if the_word in lex_dict:\n",
    "                # if it is, add to the value\n",
    "                sentiment_max += lex_dict[the_word]\n",
    "                #print(the_word, lex_dict[the_word])\n",
    "        #print(tweet_lines[i])\n",
    "        # print it out!\n",
    "        print(\"Tweet sentiment:\", sentiment_max, \"\\n\")\n",
    "    tweet_contents.close()\n",
    "\n",
    "## MAIN \n",
    "tweet_sentiment(\"tweets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
